{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ahpy\n",
    "\n",
    "# Carga de los archivos\n",
    "shipping = pd.read_excel(\"Datos_limpios.xlsx\", sheet_name=\"Shipping Detail Report\")\n",
    "labor = pd.read_excel(\"Datos_limpios.xlsx\", sheet_name=\"Labor Activity Report\")\n",
    "\n",
    "# Unificar formatos de SKU, fechas, y tipos de datos\n",
    "shipping[\"SKU\"] = shipping[\"SKU\"].astype(str).str.upper()\n",
    "labor[\"SKU\"] = labor[\"SKU\"].astype(str).str.upper()\n",
    "\n",
    "# dividimos por fecha\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "shipping_summary = (\n",
    "    shipping.groupby(\"SKU\")\n",
    "    .agg({\n",
    "        \"Qty Shipped\": \"sum\",\n",
    "        \"Weight [Kg]\": \"sum\",\n",
    "        \"Boxes\": \"sum\"\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# clasificacion ABC pareto\n",
    "shipping_summary = shipping_summary.sort_values(\"Qty Shipped\", ascending=False)\n",
    "shipping_summary[\"cum%\"] = 100 * shipping_summary[\"Qty Shipped\"].cumsum() / shipping_summary[\"Qty Shipped\"].sum()\n",
    "\n",
    "shipping_summary[\"ABC_class\"] = pd.cut(\n",
    "    shipping_summary[\"cum%\"],\n",
    "    bins=[0, 80, 90, 100],\n",
    "    labels=[\"A\", \"B\", \"C\"]\n",
    ")\n",
    "\n",
    "comparisons = {\n",
    "    ('Qty Shipped', 'Weight [Kg]'): 5, ('Qty Shipped', 'Boxes'):9,\n",
    "    ('Weight [Kg]', 'Boxes'): 4\n",
    "}\n",
    "\n",
    "criteria = ahpy.Compare('Criterios', comparisons, precision=3, random_index='saaty')\n",
    "\n",
    "print(criteria.report())\n",
    "print(\"Pesos:\", criteria.target_weights)\n",
    "print(\"Consistencia:\", criteria.consistency_ratio)\n",
    "\n",
    "# ABC con AHP\n",
    "# Normalizar columnas y crear nuevas con sufijo \"_norm\"\n",
    "for col in [\"Qty Shipped\", \"Weight [Kg]\", \"Boxes\"]:\n",
    "    shipping_summary[f\"{col}_norm\"] = shipping_summary[col] / shipping_summary[col].max()\n",
    "\n",
    "# Calcular AHP_score usando las columnas normalizadas\n",
    "shipping_summary['AHP_score'] = (\n",
    "    shipping_summary['Qty Shipped_norm'] * criteria.target_weights['Qty Shipped'] +\n",
    "    shipping_summary['Weight [Kg]_norm'] * criteria.target_weights['Weight [Kg]'] +\n",
    "    shipping_summary['Boxes_norm'] * criteria.target_weights['Boxes']\n",
    ")\n",
    "\n",
    "shipping_summary = shipping_summary.sort_values('AHP_score', ascending=False)\n",
    "shipping_summary['cum_AHP%'] = shipping_summary['AHP_score'].cumsum() / shipping_summary['AHP_score'].sum()\n",
    "\n",
    "def categoria(x):\n",
    "    if x <= 0.8: return 'A'\n",
    "    elif x <= 0.9: return 'B'\n",
    "    else: return 'C'\n",
    "\n",
    "shipping_summary['AHP_class'] = shipping_summary['cum_AHP%'].apply(categoria)\n",
    "\n",
    "print(shipping_summary['AHP_class'].value_counts())\n",
    "print(shipping_summary['ABC_class'].value_counts())\n",
    "\n",
    "# metricas por clase A, puede cambiar\n",
    "# miramos las clases en clase A en AHP cuanto porcentage representan de qty, weight y boxes\n",
    "# Filtramos solo los de clase A\n",
    "df_A = shipping_summary[shipping_summary['AHP_class'] == 'A']\n",
    "\n",
    "# Calculamos los totales\n",
    "total_qty = shipping_summary['Qty Shipped'].sum()\n",
    "total_weight = shipping_summary['Weight [Kg]'].sum()\n",
    "total_boxes = shipping_summary['Boxes'].sum()\n",
    "\n",
    "# Calculamos los totales de la clase A\n",
    "A_qty = df_A['Qty Shipped'].sum()\n",
    "A_weight = df_A['Weight [Kg]'].sum()\n",
    "A_boxes = df_A['Boxes'].sum()\n",
    "\n",
    "# Calculamos los porcentajes\n",
    "pct_qty_A = 100 * A_qty / total_qty\n",
    "pct_weight_A = 100 * A_weight / total_weight\n",
    "pct_boxes_A = 100 * A_boxes / total_boxes\n",
    "\n",
    "# Mostramos resultados\n",
    "print(f\"Clase A representa:\")\n",
    "print(f\"- {pct_qty_A:.2f}% del total de Qty Shipped\")\n",
    "print(f\"- {pct_weight_A:.2f}% del total de Weight [Kg]\")\n",
    "print(f\"- {pct_boxes_A:.2f}% del total de Boxes\")\n",
    "\n",
    "\n",
    "# boxplot para gráficar\n",
    "# Crear figura y ejes\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 8))  # 3 filas, 2 columnas\n",
    "\n",
    "# Primera fila\n",
    "sns.boxplot(data=shipping_summary, hue='AHP_class', y='Qty Shipped', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Qty Shipped - AHP_class')\n",
    "\n",
    "sns.boxplot(data=shipping_summary, hue='ABC_class', y='Qty Shipped', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Qty Shipped - ABC_class')\n",
    "\n",
    "# Segunda fila\n",
    "sns.boxplot(data=shipping_summary, hue='AHP_class', y='Weight [Kg]', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Weight [Kg] - AHP_class')\n",
    "\n",
    "sns.boxplot(data=shipping_summary, hue='ABC_class', y='Weight [Kg]', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Weight [Kg] - ABC_class')\n",
    "\n",
    "# Tercera fila\n",
    "sns.boxplot(data=shipping_summary, hue='AHP_class', y='Boxes', ax=axes[2, 0])\n",
    "axes[2, 0].set_title('Boxes - AHP_class')\n",
    "\n",
    "sns.boxplot(data=shipping_summary, hue='ABC_class', y='Boxes', ax=axes[2, 1])\n",
    "axes[2, 1].set_title('Boxes - ABC_class')\n",
    "\n",
    "# Ajustar diseño\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# métricas de similitud\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "features = ['Qty Shipped', 'Weight [Kg]', 'Boxes']\n",
    "X = shipping_summary[features].values\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "df_scaled = shipping_summary.copy()\n",
    "df_scaled[features] = Xs\n",
    "\n",
    "# función para métricas por clase\n",
    "def metrics_por_clase(df, features):\n",
    "    results = {}\n",
    "    for clase, sub in df.groupby('AHP_class'):\n",
    "        Xc = sub[features].values\n",
    "        n = len(Xc)\n",
    "        if n <= 1:\n",
    "            results[clase] = {\n",
    "                'n': n,\n",
    "                'mean_cosine_similarity': np.nan,\n",
    "                'median_cosine_similarity': np.nan,\n",
    "                'mean_euclid_distance': np.nan,\n",
    "                'score_cv': (sub['AHP_score'].std()/sub['AHP_score'].mean()) if sub['AHP_score'].mean()!=0 else np.nan\n",
    "            }\n",
    "            continue\n",
    "\n",
    "        # similitud coseno par-a-par (sin diagonal)\n",
    "        cos = cosine_similarity(Xc)\n",
    "        # extraer valores por encima de diagonal\n",
    "        iu = np.triu_indices_from(cos, k=1)\n",
    "        cos_values = cos[iu]\n",
    "\n",
    "        # distancias euclidianas\n",
    "        dists = pairwise_distances(Xc, metric='euclidean')\n",
    "        dists_values = dists[iu]\n",
    "\n",
    "        results[clase] = {\n",
    "            'n': n,\n",
    "            'mean_cosine_similarity': float(np.mean(cos_values)),\n",
    "            'median_cosine_similarity': float(np.median(cos_values)),\n",
    "            'mean_euclid_distance': float(np.mean(dists_values)),\n",
    "            'score_cv': float(sub['AHP_score'].std()/sub['AHP_score'].mean()) if sub['AHP_score'].mean()!=0 else np.nan\n",
    "        }\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "res_clase = metrics_por_clase(df_scaled, features)\n",
    "res_clase.head()\n",
    "\n",
    "# silhouette requiere al menos 2 labels y más de 1 muestra por label en la práctica\n",
    "labels = df_scaled['AHP_class'].values\n",
    "Xall = df_scaled[features].values\n",
    "\n",
    "sil = silhouette_score(Xall, labels)  # entre -1 y 1\n",
    "db = davies_bouldin_score(Xall, labels)\n",
    "ch = calinski_harabasz_score(Xall, labels)\n",
    "\n",
    "print(\"Silhouette:\", sil)\n",
    "print(\"Davies-Bouldin:\", db)\n",
    "print(\"Calinski-Harabasz:\", ch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b03b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "\"\"\"\n",
    "App Streamlit: clasificación ABC vs AHP para Shipping y Labor.\n",
    "Mantener nombres de pestañas: \"Shipping Detail Report\" y \"Labor Activity Report\".\n",
    "\"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import ahpy\n",
    "\n",
    "st.set_page_config(layout=\"wide\", page_title=\"ABC vs AHP Dashboard\")\n",
    "\n",
    "# ---------------------------\n",
    "# Util: funciones centrales\n",
    "# ---------------------------\n",
    "\n",
    "def compute_summary(df, sku_col='SKU', aggregations=None):\n",
    "    \"\"\"\n",
    "    Agrupa por SKU y devuelve un resumen con Qty Shipped, Weight [Kg], Boxes.\n",
    "    Si las columnas no existen, intenta encontrar nombres parecidos.\n",
    "    \"\"\"\n",
    "    # Por defecto, usar estas columnas si existen\n",
    "    defaults = {'Qty Shipped': 'Qty Shipped', 'Weight [Kg]': 'Weight [Kg]', 'Boxes': 'Boxes'}\n",
    "    if aggregations is None:\n",
    "        aggregations = defaults\n",
    "    # Asegurar existencia de columnas: si no existen, crear columnas con 0\n",
    "    for col in aggregations.values():\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    # Agrupar\n",
    "    summary = df.groupby(sku_col).agg({\n",
    "        aggregations['Qty Shipped']: 'sum',\n",
    "        aggregations['Weight [Kg]']: 'sum',\n",
    "        aggregations['Boxes']: 'sum'\n",
    "    }).reset_index().rename(columns={\n",
    "        aggregations['Qty Shipped']: 'Qty Shipped',\n",
    "        aggregations['Weight [Kg]']: 'Weight [Kg]',\n",
    "        aggregations['Boxes']: 'Boxes'\n",
    "    })\n",
    "    # Evitar NaNs\n",
    "    summary[['Qty Shipped','Weight [Kg]','Boxes']] = summary[['Qty Shipped','Weight [Kg]','Boxes']].fillna(0)\n",
    "    return summary\n",
    "\n",
    "def compute_abc(summary, qty_col='Qty Shipped', cuts=[80,90]):\n",
    "    \"\"\"\n",
    "    Clasificación ABC clásica por Pareto basada en `qty_col`.\n",
    "    - cuts: lista con percentiles acumulativos (ej [80,90]) => A: <=80, B: >80-90, C: >90-100\n",
    "    Devuelve summary con 'cum%', 'ABC_class'\n",
    "    \"\"\"\n",
    "    df = summary.copy()\n",
    "    # Orden descendente por qty\n",
    "    df = df.sort_values(qty_col, ascending=False).reset_index(drop=True)\n",
    "    total = df[qty_col].sum()\n",
    "    # Si total 0, evitar división por cero; asignar 0%\n",
    "    if total == 0:\n",
    "        df['cum%'] = 0.0\n",
    "    else:\n",
    "        df['cum%'] = (df[qty_col].cumsum() / total) * 100\n",
    "    # Definir cortes\n",
    "    cuts_sorted = sorted(cuts)\n",
    "    def classify(x):\n",
    "        if x <= cuts_sorted[0]:\n",
    "            return 'A'\n",
    "        elif x <= cuts_sorted[1]:\n",
    "            return 'B'\n",
    "        else:\n",
    "            return 'C'\n",
    "    df['ABC_class'] = df['cum%'].apply(classify)\n",
    "    return df\n",
    "\n",
    "def compute_ahp(summary, features, comparisons_dict, cuts=[80,90]):\n",
    "    \"\"\"\n",
    "    Ejecuta AHP con ahpy usando comparisons_dict (pares de comparaciones) y calcula AHP_score.\n",
    "    - features: lista de columnas sobre las que construir el score (columnas numéricas de summary)\n",
    "    - comparisons_dict: diccionario con comparaciones en el formato {'A': {'B': value, 'C': value}, 'B': {'C':value}}\n",
    "      (compatible con ahpy.Compare)\n",
    "    Devuelve summary con columnas normalizadas, 'AHP_score', 'cum_AHP%', 'AHP_class' y retorna también el objeto criteria de ahpy.\n",
    "    \"\"\"\n",
    "    df = summary.copy().reset_index(drop=True)\n",
    "    # Normalizar columnas (col / col.max())\n",
    "    for col in features:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "        maxv = df[col].max()\n",
    "        if maxv == 0:\n",
    "            df[f'{col}_norm'] = 0.0\n",
    "        else:\n",
    "            df[f'{col}_norm'] = df[col] / maxv\n",
    "\n",
    "    # Ejecutar ahpy: Construir objeto Compare\n",
    "    try:\n",
    "        criteria = ahpy.Compare('criteria', comparisons=comparisons_dict, precision=6)\n",
    "        weights = criteria.target_weights  # dict {feature: weight}\n",
    "        # Asegurar que todos features tengan un peso (si el usuario escribió pesos directos, manejar)\n",
    "        weights_list = [weights.get(f, 0) for f in features]\n",
    "    except Exception as e:\n",
    "        # Si ahpy falla, devolver pesos iguales\n",
    "        st.warning(\"ahpy no pudo construir la matriz AHP con las comparaciones dadas. Se usarán pesos iguales.\")\n",
    "        weights_list = [1.0/len(features)]*len(features)\n",
    "        criteria = None\n",
    "\n",
    "    # Calcular AHP_score = suma(weights[i] * feature_norm)\n",
    "    # Si criteria existe, usar sus pesos; si no, usar weights_list\n",
    "    norm_cols = [f'{col}_norm' for col in features]\n",
    "    w = np.array(weights_list, dtype=float)\n",
    "    norms = df[norm_cols].fillna(0).values\n",
    "    # Normalizar pesos para que sumen 1 si no están normalizados\n",
    "    if w.sum() == 0:\n",
    "        w = np.ones(len(features))/len(features)\n",
    "    else:\n",
    "        w = w / w.sum()\n",
    "    df['AHP_score'] = norms.dot(w)\n",
    "    # cumsum por puntuación descendente\n",
    "    df = df.sort_values('AHP_score', ascending=False).reset_index(drop=True)\n",
    "    total_ahp = df['AHP_score'].sum()\n",
    "    if total_ahp == 0:\n",
    "        df['cum_AHP%'] = 0.0\n",
    "    else:\n",
    "        df['cum_AHP%'] = (df['AHP_score'].cumsum() / total_ahp) * 100\n",
    "    # Clasificación A/B/C con mismos cortes\n",
    "    cuts_sorted = sorted(cuts)\n",
    "    def classify_ahp(x):\n",
    "        if x <= cuts_sorted[0]:\n",
    "            return 'A'\n",
    "        elif x <= cuts_sorted[1]:\n",
    "            return 'B'\n",
    "        else:\n",
    "            return 'C'\n",
    "    df['AHP_class'] = df['cum_AHP%'].apply(classify_ahp)\n",
    "\n",
    "    return df, criteria\n",
    "\n",
    "def compute_similarity_metrics(summary, features, class_col='AHP_class'):\n",
    "    \"\"\"\n",
    "    Calcula métricas por clase:\n",
    "    - mean & median cosine similarity (pairwise entre elementos dentro de cada clase)\n",
    "    - mean euclidean distance (pairwise)\n",
    "    - coeficiente de variación (std/mean) del AHP_score por clase\n",
    "    También calcula índices globales: silhouette, Davies-Bouldin, Calinski-Harabasz (si aplicable).\n",
    "    Devuelve: (df_metrics_por_clase, dict_global_indices)\n",
    "    \"\"\"\n",
    "    df = summary.copy().reset_index(drop=True)\n",
    "    results = []\n",
    "    X = df[features].fillna(0).values\n",
    "    labels = df[class_col].values\n",
    "    # Por clase\n",
    "    for cls in np.unique(labels):\n",
    "        idx = np.where(labels == cls)[0]\n",
    "        sub = X[idx]\n",
    "        res = {'class': cls, 'n': len(idx)}\n",
    "        if len(idx) < 2:\n",
    "            res.update({\n",
    "                'mean_cosine_sim': np.nan,\n",
    "                'median_cosine_sim': np.nan,\n",
    "                'mean_euclidean': np.nan,\n",
    "                'cv_ahp_score': np.nan\n",
    "            })\n",
    "        else:\n",
    "            # cosine similarity matriz (pairwise), tomar upper triangle sin diagonal\n",
    "            cos_mat = cosine_similarity(sub)\n",
    "            iu = np.triu_indices_from(cos_mat, k=1)\n",
    "            cos_vals = cos_mat[iu]\n",
    "            res['mean_cosine_sim'] = np.mean(cos_vals) if cos_vals.size>0 else np.nan\n",
    "            res['median_cosine_sim'] = np.median(cos_vals) if cos_vals.size>0 else np.nan\n",
    "            # euclidian distances\n",
    "            dists = pairwise_distances(sub, metric='euclidean')\n",
    "            dists_vals = dists[iu]\n",
    "            res['mean_euclidean'] = np.mean(dists_vals) if dists_vals.size>0 else np.nan\n",
    "            # Coef de variación del AHP_score en el grupo\n",
    "            ahp_vals = df.loc[idx, 'AHP_score'].values\n",
    "            if ahp_vals.mean() == 0:\n",
    "                res['cv_ahp_score'] = np.nan\n",
    "            else:\n",
    "                res['cv_ahp_score'] = ahp_vals.std(ddof=0)/ahp_vals.mean()\n",
    "        results.append(res)\n",
    "    df_metrics = pd.DataFrame(results)\n",
    "\n",
    "    # Global indices: necesitan al menos 2 clusters y cada cluster con >=2 elementos para silhouette\n",
    "    global_idx = {}\n",
    "    try:\n",
    "        # silhouette requires >1 label and n_samples > n_labels\n",
    "        if len(np.unique(labels)) > 1 and X.shape[0] > len(np.unique(labels)):\n",
    "            # silhouette_score requiere al menos 2 elementos por cluster? Actually only total > n_clusters.\n",
    "            global_idx['silhouette'] = silhouette_score(X, labels)\n",
    "        else:\n",
    "            global_idx['silhouette'] = np.nan\n",
    "    except Exception:\n",
    "        global_idx['silhouette'] = np.nan\n",
    "    try:\n",
    "        if len(np.unique(labels)) > 1:\n",
    "            global_idx['davies_bouldin'] = davies_bouldin_score(X, labels)\n",
    "            global_idx['calinski_harabasz'] = calinski_harabasz_score(X, labels)\n",
    "        else:\n",
    "            global_idx['davies_bouldin'] = np.nan\n",
    "            global_idx['calinski_harabasz'] = np.nan\n",
    "    except Exception:\n",
    "        global_idx['davies_bouldin'] = np.nan\n",
    "        global_idx['calinski_harabasz'] = np.nan\n",
    "\n",
    "    return df_metrics, global_idx\n",
    "\n",
    "# ---------------------------\n",
    "# UI: Upload y selección inicial\n",
    "# ---------------------------\n",
    "st.title(\"Clasificación ABC vs AHP — Shipping & Labor\")\n",
    "st.markdown(\"**Instrucciones:** Subir un archivo Excel que contenga *exactamente* las hojas `Shipping Detail Report` y `Labor Activity Report` (no renombres las pestañas).\")\n",
    "\n",
    "uploaded = st.file_uploader(\"Sube archivo Excel (.xlsx) con ambas hojas\", type=['xlsx'])\n",
    "\n",
    "if not uploaded:\n",
    "    st.info(\"Sube un archivo Excel para empezar. Asegúrate de que las hojas se llamen exactamente 'Shipping Detail Report' y 'Labor Activity Report'.\")\n",
    "    st.stop()\n",
    "\n",
    "# Cargar archivos\n",
    "try:\n",
    "    xls = pd.ExcelFile(uploaded)\n",
    "    available_sheets = xls.sheet_names\n",
    "    if \"Shipping Detail Report\" not in available_sheets or \"Labor Activity Report\" not in available_sheets:\n",
    "        st.error(\"El archivo no contiene una o ambas hojas requeridas: 'Shipping Detail Report' y 'Labor Activity Report'. Verifica el archivo.\")\n",
    "        st.stop()\n",
    "    df_ship_raw = pd.read_excel(xls, sheet_name=\"Shipping Detail Report\")\n",
    "    df_labor_raw = pd.read_excel(xls, sheet_name=\"Labor Activity Report\")\n",
    "except Exception as e:\n",
    "    st.exception(e)\n",
    "    st.stop()\n",
    "\n",
    "st.sidebar.header(\"Configuración general\")\n",
    "view_mode = st.sidebar.selectbox(\"Ver dataset\", options=['Shipping','Labor'])\n",
    "# Preview y selección de columna fecha\n",
    "st.subheader(\"Preview y selección de columna fecha\")\n",
    "\n",
    "col1, col2 = st.columns(2)\n",
    "with col1:\n",
    "    st.write(\"**Shipping - head()**\")\n",
    "    st.dataframe(df_ship_raw.head())\n",
    "    ship_date_col = st.selectbox(\"Selecciona columna fecha (Shipping)\", options=list(df_ship_raw.columns), index=0, key='ship_date')\n",
    "with col2:\n",
    "    st.write(\"**Labor - head()**\")\n",
    "    st.dataframe(df_labor_raw.head())\n",
    "    labor_date_col = st.selectbox(\"Selecciona columna fecha (Labor)\", options=list(df_labor_raw.columns), index=0, key='labor_date')\n",
    "\n",
    "# Convertir a datetime y pedir rango (aplicado a ambos)\n",
    "df_ship_raw[ship_date_col] = pd.to_datetime(df_ship_raw[ship_date_col], errors='coerce')\n",
    "df_labor_raw[labor_date_col] = pd.to_datetime(df_labor_raw[labor_date_col], errors='coerce')\n",
    "\n",
    "min_date = min(df_ship_raw[ship_date_col].min(), df_labor_raw[labor_date_col].min())\n",
    "max_date = max(df_ship_raw[ship_date_col].max(), df_labor_raw[labor_date_col].max())\n",
    "\n",
    "st.sidebar.subheader(\"Filtrar rango de fechas (aplicado a ambos datasets)\")\n",
    "date_range = st.sidebar.date_input(\"Rango fechas\", value=[min_date.date(), max_date.date()], min_value=min_date.date(), max_value=max_date.date())\n",
    "start, end = pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1])\n",
    "\n",
    "# Aplicar filtro a ambos datasets\n",
    "df_ship = df_ship_raw[(df_ship_raw[ship_date_col] >= start) & (df_ship_raw[ship_date_col] <= end)].copy()\n",
    "df_labor = df_labor_raw[(df_labor_raw[labor_date_col] >= start) & (df_labor_raw[labor_date_col] <= end)].copy()\n",
    "\n",
    "st.sidebar.write(f\"Shipping filtrado: {df_ship.shape[0]} filas | Labor filtrado: {df_labor.shape[0]} filas\")\n",
    "\n",
    "# ---------------------------\n",
    "# Parámetros ABC (umbral editable)\n",
    "# ---------------------------\n",
    "st.sidebar.subheader(\"Umbrales ABC (cortes acumulativos en %)\")\n",
    "default_cuts = [80, 90]\n",
    "cut_a = st.sidebar.slider(\"A hasta (%)\", min_value=1, max_value=99, value=default_cuts[0])\n",
    "cut_b = st.sidebar.slider(\"B hasta (%)\", min_value=cut_a+1, max_value=100, value=default_cuts[1])\n",
    "cuts = [cut_a, cut_b]\n",
    "\n",
    "# ---------------------------\n",
    "# Selección columnas SKU y agregación\n",
    "# ---------------------------\n",
    "st.sidebar.subheader(\"Columnas clave y agregación\")\n",
    "sku_col_ship = st.sidebar.text_input(\"Nombre de columna SKU (Shipping)\", value=\"SKU\")\n",
    "qty_col_ship = st.sidebar.text_input(\"Nombre Qty Shipped (Shipping)\", value=\"Qty Shipped\")\n",
    "weight_col_ship = st.sidebar.text_input(\"Nombre Weight [Kg] (Shipping)\", value=\"Weight [Kg]\")\n",
    "boxes_col_ship = st.sidebar.text_input(\"Nombre Boxes (Shipping)\", value=\"Boxes\")\n",
    "\n",
    "sku_col_labor = st.sidebar.text_input(\"Nombre de columna SKU (Labor)\", value=\"SKU\")\n",
    "# Sugerir métricas de labor (por ejemplo Hours, Headcount) - el usuario selecciona las columnas que quiera usar para AHP\n",
    "# No forzamos nombres específicos para labor; permitimos seleccionar más abajo.\n",
    "\n",
    "# ---------------------------\n",
    "# Selección de variables para AHP (features)\n",
    "# ---------------------------\n",
    "st.sidebar.subheader(\"Selección de variables para AHP\")\n",
    "if view_mode == 'Shipping':\n",
    "    # Mostrar columnas sugeridas para usar en AHP\n",
    "    candidate_features_ship = [qty_col_ship, weight_col_ship, boxes_col_ship]\n",
    "    use_features = st.sidebar.multiselect(\"Selecciona variables para AHP (Shipping)\", options=candidate_features_ship, default=candidate_features_ship)\n",
    "else:\n",
    "    # Para labor, permitir seleccionar columnas del dataframe lab\n",
    "    candidate_features_labor = list(df_labor.columns)\n",
    "    use_features = st.sidebar.multiselect(\"Selecciona variables para AHP (Labor)\", options=candidate_features_labor, default=candidate_features_labor[:3])\n",
    "\n",
    "# ---------------------------\n",
    "# Panel AHP: subir imagen explicativa y editar matriz\n",
    "# ---------------------------\n",
    "st.header(\"Panel AHP\")\n",
    "st.markdown(\"Sube una imagen explicativa (opcional) que se mostrará encima de la matriz de comparaciones. Luego edita la matriz o los pesos directamente.\")\n",
    "\n",
    "uploaded_img = st.file_uploader(\"Sube imagen explicativa (PNG/JPG)\", type=['png','jpg','jpeg'])\n",
    "if uploaded_img:\n",
    "    st.image(uploaded_img, caption=\"Imagen explicativa AHP\", use_column_width=True)\n",
    "\n",
    "# Crear interfaz para editar matriz de comparaciones entre criterios (features)\n",
    "st.subheader(\"Editar matriz de comparaciones (AHP)\")\n",
    "st.markdown(\"Usa valores 1,3,5,7,9 y recíprocos (1/3, 1/5...). Puedes editar cada par. Alternativa: editar pesos directos.\")\n",
    "\n",
    "# Preparar estructura de comparaciones para ahpy: dict of dicts\n",
    "features = use_features.copy()\n",
    "if len(features) < 2:\n",
    "    st.warning(\"Selecciona al menos 2 features para ejecutar AHP.\")\n",
    "    st.stop()\n",
    "\n",
    "# Construir dataframe triangular para edición\n",
    "pairs = []\n",
    "for i in range(len(features)):\n",
    "    for j in range(i+1, len(features)):\n",
    "        pairs.append({'feature_i': features[i], 'feature_j': features[j], 'value': 1.0})\n",
    "\n",
    "pairs_df = pd.DataFrame(pairs)\n",
    "# Mostrar editor del dataframe\n",
    "edited_pairs = st.experimental_data_editor(pairs_df, num_rows=\"dynamic\", key=\"ahp_pairs_editor\")\n",
    "\n",
    "# Convertir a comparisons dict para ahpy\n",
    "comparisons = {}\n",
    "for _, row in edited_pairs.iterrows():\n",
    "    i = row['feature_i']\n",
    "    j = row['feature_j']\n",
    "    val = float(row['value']) if pd.notna(row['value']) else 1.0\n",
    "    comparisons.setdefault(i, {})[j] = val\n",
    "\n",
    "# Opción alternativa: editar pesos directos\n",
    "st.markdown(\"**Opción:** editar pesos directos (sobreescribe la matriz si se usan).\")\n",
    "weights_manual = {}\n",
    "use_manual_weights = st.checkbox(\"Usar pesos manuales (si activo, la matriz se ignorará para pesos)\")\n",
    "if use_manual_weights:\n",
    "    col1, col2 = st.columns(2)\n",
    "    for f in features:\n",
    "        weights_manual[f] = col1.number_input(f\"Peso {f}\", min_value=0.0, value=1.0, step=0.1, key=f\"w_{f}\")\n",
    "    # Normalizar pesos\n",
    "    total_w = sum(weights_manual.values())\n",
    "    if total_w == 0:\n",
    "        # evitar dividir por cero\n",
    "        for k in weights_manual:\n",
    "            weights_manual[k] = 1.0/len(weights_manual)\n",
    "    else:\n",
    "        for k in weights_manual:\n",
    "            weights_manual[k] = weights_manual[k]/total_w\n",
    "\n",
    "# ---------------------------\n",
    "# Botón ejecutar\n",
    "# ---------------------------\n",
    "if st.button(\"Ejecutar clasificación y métricas\"):\n",
    "    # Elegir dataset\n",
    "    if view_mode == 'Shipping':\n",
    "        df_use = df_ship.copy()\n",
    "        sku_col = sku_col_ship\n",
    "        aggregations = {'Qty Shipped': qty_col_ship, 'Weight [Kg]': weight_col_ship, 'Boxes': boxes_col_ship}\n",
    "    else:\n",
    "        df_use = df_labor.copy()\n",
    "        sku_col = sku_col_labor\n",
    "        # Asumir que user seleccionó features pertinentes; si no existen, compute_summary rellenará con ceros\n",
    "        aggregations = {'Qty Shipped': use_features[0] if len(use_features)>0 else use_features[0], 'Weight [Kg]': use_features[1] if len(use_features)>1 else use_features[0], 'Boxes': use_features[2] if len(use_features)>2 else use_features[0]}\n",
    "\n",
    "    # Calcular summary por SKU\n",
    "    summary = compute_summary(df_use, sku_col=sku_col, aggregations=aggregations)\n",
    "\n",
    "    # ABC clásico\n",
    "    abc_df = compute_abc(summary, qty_col='Qty Shipped', cuts=cuts)\n",
    "\n",
    "    # AHP: construir comparisons dict (si usan pesos manuales, creamos comparisons que reflejen esos pesos)\n",
    "    if use_manual_weights:\n",
    "        # Si el usuario quiere usar pesos manuales, construiremos un faux-comparisons dict que refleje ratios de pesos\n",
    "        comp_manual = {}\n",
    "        for i in range(len(features)):\n",
    "            for j in range(i+1, len(features)):\n",
    "                a = features[i]; b = features[j]\n",
    "                val = weights_manual[a] / weights_manual[b] if weights_manual[b] != 0 else 1.0\n",
    "                comp_manual.setdefault(a, {})[b] = float(val)\n",
    "        comparisons_to_use = comp_manual\n",
    "    else:\n",
    "        comparisons_to_use = comparisons\n",
    "\n",
    "    # Ejecutar AHP y obtener summary ahp\n",
    "    ahp_summary, criteria = compute_ahp(summary, features=features, comparisons_dict=comparisons_to_use, cuts=cuts)\n",
    "\n",
    "    # Unir ABC clásico y AHP en un solo df comparativo (usar SKU como key)\n",
    "    merged = pd.merge(abc_df[['SKU','Qty Shipped','Weight [Kg]','Boxes','cum%','ABC_class']], \n",
    "                      ahp_summary[['SKU','AHP_score','cum_AHP%','AHP_class'] + [f'{f}_norm' for f in features]],\n",
    "                      on='SKU', how='outer').fillna(0)\n",
    "\n",
    "    st.header(\"Resultados comparativos\")\n",
    "    st.subheader(\"Tabla de resumen (por SKU)\")\n",
    "    st.dataframe(merged)\n",
    "\n",
    "    # Mostrar conteos por clase\n",
    "    colA, colB, colC = st.columns(3)\n",
    "    with colA:\n",
    "        st.metric(\"ABC - A count\", int((merged['ABC_class']=='A').sum()))\n",
    "        st.metric(\"AHP - A count\", int((merged['AHP_class']=='A').sum()))\n",
    "    with colB:\n",
    "        st.metric(\"ABC - B count\", int((merged['ABC_class']=='B').sum()))\n",
    "        st.metric(\"AHP - B count\", int((merged['AHP_class']=='B').sum()))\n",
    "    with colC:\n",
    "        st.metric(\"ABC - C count\", int((merged['ABC_class']=='C').sum()))\n",
    "        st.metric(\"AHP - C count\", int((merged['AHP_class']=='C').sum()))\n",
    "\n",
    "    # Mostrar reporte ahpy si estuvo bien construido\n",
    "    if criteria is not None:\n",
    "        st.subheader(\"Reporte AHP (ahpy)\")\n",
    "        try:\n",
    "            st.text(criteria.report())\n",
    "        except Exception:\n",
    "            st.write(\"No se pudo renderizar report() de ahpy; mostrando pesos y consistency_ratio si están disponibles.\")\n",
    "            st.write(\"Pesos (target_weights):\", criteria.target_weights)\n",
    "            try:\n",
    "                st.write(\"Consistency ratio:\", criteria.consistency_ratio)\n",
    "            except Exception:\n",
    "                st.write(\"Consistency ratio no disponible.\")\n",
    "\n",
    "    else:\n",
    "        st.warning(\"No se generó un objeto 'criteria' válido. Se usaron pesos iguales o manuales.\")\n",
    "\n",
    "    # Métricas de similitud\n",
    "    st.subheader(\"Métricas de similitud por clase y globales\")\n",
    "    # Para métricas, usar columnas numéricas escogidas (features)\n",
    "    merged_for_metrics = merged.copy()\n",
    "    # Asegurarse de tener AHP_score y las features normalizadas\n",
    "    metrics_df, global_indices = compute_similarity_metrics(merged_for_metrics, features=[f'{f}_norm' for f in features], class_col='AHP_class')\n",
    "    st.dataframe(metrics_df)\n",
    "    st.write(\"Índices globales:\", global_indices)\n",
    "\n",
    "    # Boxplots comparativos: Qty Shipped / Weight [Kg] / Boxes vs classes (AHP_class y ABC_class)\n",
    "    st.subheader(\"Boxplots comparativos\")\n",
    "    fig_col1, fig_col2 = st.columns(2)\n",
    "    with fig_col1:\n",
    "        st.markdown(\"**Qty Shipped por AHP_class (Plotly interactivo)**\")\n",
    "        try:\n",
    "            fig_px = px.box(merged, x='AHP_class', y='Qty Shipped', points=\"all\", title=\"Qty Shipped vs AHP_class\")\n",
    "            st.plotly_chart(fig_px, use_container_width=True)\n",
    "        except Exception as e:\n",
    "            st.write(\"No se pudo generar Plotly:\", e)\n",
    "    with fig_col2:\n",
    "        st.markdown(\"**Qty Shipped por ABC_class (Plotly interactivo)**\")\n",
    "        try:\n",
    "            fig_px2 = px.box(merged, x='ABC_class', y='Qty Shipped', points=\"all\", title=\"Qty Shipped vs ABC_class\")\n",
    "            st.plotly_chart(fig_px2, use_container_width=True)\n",
    "        except Exception as e:\n",
    "            st.write(\"No se pudo generar Plotly:\", e)\n",
    "\n",
    "    # Generar también gráficos estáticos con matplotlib/seaborn (por compatibilidad con el ejemplo)\n",
    "    st.markdown(\"**Gráficos estáticos (matplotlib/seaborn)**\")\n",
    "    fig, axes = plt.subplots(1,3, figsize=(18,5))\n",
    "    sns.boxplot(data=merged, x='AHP_class', y='Qty Shipped', ax=axes[0])\n",
    "    axes[0].set_title(\"Qty Shipped vs AHP_class\")\n",
    "    sns.boxplot(data=merged, x='AHP_class', y='Weight [Kg]', ax=axes[1])\n",
    "    axes[1].set_title(\"Weight [Kg] vs AHP_class\")\n",
    "    sns.boxplot(data=merged, x='AHP_class', y='Boxes', ax=axes[2])\n",
    "    axes[2].set_title(\"Boxes vs AHP_class\")\n",
    "    st.pyplot(fig)\n",
    "\n",
    "    # Botón de descarga\n",
    "    st.subheader(\"Descargar resumen\")\n",
    "    to_download = merged.copy()\n",
    "    csv = to_download.to_csv(index=False).encode('utf-8')\n",
    "    st.download_button(label=\"Descargar CSV\", data=csv, file_name=f\"{view_mode}_summary.csv\", mime='text/csv')\n",
    "\n",
    "    # Mensajes de error/advertencia\n",
    "    # Consistencia AHP\n",
    "    try:\n",
    "        if criteria is not None:\n",
    "            cr = getattr(criteria, 'consistency_ratio', None)\n",
    "            if cr is not None:\n",
    "                if cr > 0.1:\n",
    "                    st.warning(f\"Consistency ratio AHP = {cr:.3f} > 0.1. Revisa la matriz de comparaciones; puede no ser consistente.\")\n",
    "                else:\n",
    "                    st.success(f\"Consistency ratio AHP = {cr:.3f}. Consistencia aceptable.\")\n",
    "    except Exception:\n",
    "        st.info(\"No fue posible obtener la consistency_ratio del objeto ahpy.\")\n",
    "\n",
    "    st.success(\"Ejecución completada.\")\n",
    "\n",
    "# Fin del botón ejecutar\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hikvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
